"""Defines the Lark grammar and pre-cleaning helper function for execution.txt files."""

import re

from lark import Lark

execution_file_grammar = r"""
start: header (point_groups | time_section | grade_section | junkline)*

header: timestamp filename
timestamp: /\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\+\d{2}:\d{2}/
filename: /[^\n]+/

point_groups: "Point groups:" (group_name ":" points_info)*

group_name: /[^\n:]+/

points_info: points_score "(" points_weighed ")"
points_score: points "/" points_max
points_weighed: weighed_points "/" weighed_max

points: NUMBER
points_max: NUMBER
weighed_points: NUMBER
weighed_max: NUMBER

!time_section: "Aeg:" ms_time "ms"
ms_time: NUMBER

grade_section: GRADE_HEADER grade_value
GRADE_HEADER: /Grade\s*:=>>/
grade_value: NUMBER

junkline: /.+/  -> skip_line

%import common.WS
%import common.NUMBER

%ignore WS
"""

lark_parser = Lark(execution_file_grammar, parser="lalr", maybe_placeholders=False, propagate_positions=False)

BLOCK_COMMENT_RE = re.compile(r'<\|--.*?--\|>', flags=re.DOTALL)

GARBAGE_PATTERNS = [
    r"Dendrologist:.*",
    r"OpenJDK 64-Bit Server VM warning:.*",
    r"Cleared leaderboard score.*",
    r"./vpl_execution",
    r"Location.*",
    r"^:.*$",
    r"^Killed.*$",
    r"^executionFinished.*",
]

GARBAGE_LINE_RE = re.compile("|".join(GARBAGE_PATTERNS), flags=re.MULTILINE)


def pre_clean_execution(content: str) -> str:
    """
    Generated by AI assistant.

    Preprocesses the given content by removing unwanted patterns.

    This function performs a cleaning operation on the input string by removing
    unwanted patterns using a predefined regular expression.
    It ensures the content is sanitized before further processing.

    Args:
        content: The input string that needs to be cleaned.

    Returns:
        str: A sanitized string with unwanted patterns removed.
    """
    content = BLOCK_COMMENT_RE.sub('', content)
    content = GARBAGE_LINE_RE.sub('', content)
    return content.strip()
